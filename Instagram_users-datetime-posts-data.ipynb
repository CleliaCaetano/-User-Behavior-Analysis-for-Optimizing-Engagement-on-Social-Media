{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53da9db9",
   "metadata": {},
   "source": [
    "### Tasks:\n",
    "- As a social media platform operator offering various features such as posts, messaging, and\n",
    "recommendations, we aim to improve user engagement and optimize personalized content delivery.\n",
    "- To achieve this, we seek to analyze and categorize user behavior patterns based on their activity on the\n",
    "platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d70cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\cleli\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\cleli\\AppData\\Local\\Temp/ipykernel_1644/135091114.py\", line 3, in <module>\n",
      "    import pandas as pd # Data manipulation, provides structures and functions.\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\", line 80, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\numexpr\\__init__.py\", line 26, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\cleli\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\cleli\\AppData\\Local\\Temp/ipykernel_1644/135091114.py\", line 3, in <module>\n",
      "    import pandas as pd # Data manipulation, provides structures and functions.\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\", line 80, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\cleli\\anaconda3\\lib\\site-packages\\bottleneck\\__init__.py\", line 2, in <module>\n",
      "    from .reduce import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "# Importing Libraries:\n",
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "# Visualization\n",
    "import seaborn as sns # provide statistical graphs\n",
    "import plotly.graph_objects as go\n",
    "   \n",
    "# We can suppress the warnings messages that may appear when we run our code.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f82f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('Instagram_users-datetime-posts-data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the category of each column.\n",
    "# check which columns contains categorical variables (object) and numerical variables (int64, float64).\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dca521",
   "metadata": {},
   "source": [
    "### Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc060590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of unique values in each column.\n",
    "df.nunique(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15016a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that are irrelevant.\n",
    "df.drop(['User uuid', 'Likes', 'Days passed from post', 'Likes Score', 'Numer of Tags', 'Numer of Comments', 'Year'],\n",
    "            axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the first 5 rows.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466bfb59",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e722865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b474fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of occurrences of unique values in the 'Type' column\n",
    "df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurrences\\n\",\n",
    "type_counts = df['Type'].value_counts()\n",
    "\n",
    "# Create a new DataFrame to combine counts\n",
    "type_summary = pd.DataFrame({'Count': type_counts})\n",
    "    \n",
    "# List of colors (one for each bar)\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']  # Example color list\n",
    "    \n",
    "# Create an interactive bar chart with Plotly\n",
    "fig = go.Figure()\n",
    "    \n",
    "# Add the bars with different colors\n",
    "fig.add_trace(go.Bar(\n",
    "x=type_summary.index,\n",
    "y=type_summary['Count'],\n",
    "marker=dict(color=colors)  # Assign colors from the list\n",
    "    ))\n",
    "    \n",
    "# Update layout to make it more interactive\n",
    "fig.update_layout(\n",
    "title='Distribution of Users by Type'\n",
    "xaxis_title='Type'\n",
    "yaxis_title='Count',\n",
    "plot_bgcolor='grey',  # Set background to grey\n",
    "paper_bgcolor='grey',  # Set paper background to grey\n",
    "font=dict(color='white'),  # Set font color to white for contrast\n",
    "hovermode='closest',  # Enable hover\n",
    "xaxis=dict(tickangle=45),  # Rotate x-axis labels for better readability\n",
    "height=400,  # Adjust height of the plot\n",
    "width=600,  # Adjust width of the plot\n",
    "    \n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a6f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 'Date Posted' column to the datetime64[ns] format to performing specific types of analysis.\n",
    "df['Date Posted'] = df['Date Posted'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec532ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of occurrences of unique values in the 'Date Posted' column.\n",
    "df['Date Posted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7ad0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the 'Date Posted' column as the index label (making that column the primary reference point).\n",
    "df.set_index('Date Posted', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf6fae",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc2af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Selecting numerical columns for outlier detection\n",
    "numeric_columns = ['Month', 'Day', 'Hour', 'Minute']\n",
    "\n",
    "# Define custom colors for the boxes\n",
    "box_colors = {\n",
    "    'Month': 'lightblue',\n",
    "    'Day': 'lightgreen',\n",
    "    'Hour': 'lightcoral',\n",
    "    'Minute': 'lightsalmon'\n",
    "}\n",
    "\n",
    "# Create a figure for the box plots\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add box plots for each numeric column\n",
    "for column in numeric_columns:\n",
    "    fig.add_trace(go.Box(\n",
    "        y=df[column],\n",
    "        name=column,\n",
    "        boxmean='sd',  # Add a mean and standard deviation for better visibility\n",
    "        fillcolor=box_colors.get(column, 'lightgray'),  # Set box fill color from dictionary\n",
    "        line=dict(color='white'),  # Set outline color for the box\n",
    "        marker=dict(color='black'),  # Set color for the outlier markers\n",
    "        boxpoints='outliers',  # Show only outliers, not all points\n",
    "        jitter=0.5,  # Spread out the outliers slightly for clarity\n",
    "        pointpos=0,  # Position of the outliers on the x-axis\n",
    "    ))\n",
    "\n",
    "# Update layout for a simple, interactive plot\n",
    "fig.update_layout(\n",
    "    title='Box Plots for Outlier Detection',\n",
    "    xaxis_title='Columns',\n",
    "    yaxis_title='Values',\n",
    "    plot_bgcolor='grey',  # Set background color to grey\n",
    "    paper_bgcolor='grey',  # Set paper background to grey\n",
    "    font=dict(color='white'),  # Set font color to white for contrast\n",
    "    height=400,  # Adjust height of the plot\n",
    "    width=600,  # Adjust width of the plot\n",
    "    showlegend=False  # Disable legend to make it simpler\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f746c02",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"# check the size of tha DataFrame (rows and columns).\\n\",\n",
    "    \"df.shape\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"# compute and interpret the mean, median, quartiles and standard deviation of the dataset.\\n\",\n",
    "    \"df.describe().round(2)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2d151b",
   "metadata": {},
   "source": [
    "### Normal Distribution (Kurtosis Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdfb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"# List of columns to check for kurtosis\\n\",\n",
    "    \"columns_to_test = ['Month', 'Day', 'Hour', 'Minute']\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create subplots (1 row and 4 columns)\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 4, figsize=(20, 6))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize lists to store kurtosis values and column names\\n\",\n",
    "    \"kurtosis_values = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Loop over each column to test\\n\",\n",
    "    \"for i, column in enumerate(columns_to_test):\\n\",\n",
    "    \"    # Calculate kurtosis for the current column\\n\",\n",
    "    \"    kurtosis_result = stats.kurtosis(df[column], nan_policy='omit')\\n\",\n",
    "    \"    kurtosis_values.append(kurtosis_result)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Output kurtosis result and interpretation\\n\",\n",
    "    \"    print(f\\\"Kurtosis Test for '{column}':\\\")\\n\",\n",
    "    \"    print(f\\\"Kurtosis statistic: {kurtosis_result}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if abs(kurtosis_result) < 0.05:  # This threshold can be adjusted\\n\",\n",
    "    \"        print(f\\\"The data in column '{column}' follows a normal distribution.\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(f\\\"The data in column '{column}' does not follow a normal distribution.\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"-\\\" * 50)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot the histogram and normal distribution curve\\n\",\n",
    "    \"    column_data = df[column]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate mean and standard deviation for the normal distribution curve\\n\",\n",
    "    \"    mean = np.mean(column_data)\\n\",\n",
    "    \"    std_dev = np.std(column_data)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create a range of values for the x-axis (within 3 standard deviations)\\n\",\n",
    "    \"    x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 100)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate the normal distribution (PDF) using the mean and standard deviation\\n\",\n",
    "    \"    pdf = stats.norm.pdf(x, mean, std_dev)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot the histogram and normal distribution curve\\n\",\n",
    "    \"    axes[i].hist(column_data, bins=20, density=True, alpha=0.6, color='blue', label='Histogram')\\n\",\n",
    "    \"    axes[i].plot(x, pdf, color='red', linestyle='--', label='Normal Distribution')\\n\",\n",
    "    \"    axes[i].set_title(f'Kurtosis: {kurtosis_result:.2f}\\\\n{column}')\\n\",\n",
    "    \"    axes[i].set_xlabel(column)\\n\",\n",
    "    \"    axes[i].set_ylabel('Density')\\n\",\n",
    "    \"    axes[i].legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Adjust layout for better readability\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b56c28a",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12145d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and 'Date Posted' is your index as datetime\n",
    "df['Date Posted'] = pd.to_datetime(df.index)  # Convert index to datetime if it's not already\n",
    "   \n",
    "# Extract time-based features from the 'Date Posted' column\n",
    "df['Hour'] = df['Date Posted'].dt.hour  # Hour of the day (0-23)\n",
    "df['Day'] = df['Date Posted'].dt.day     # Day of the month (1-31)\n",
    "df['Month'] = df['Date Posted'].dt.month # Month of the year (1-12)\n",
    "df['Day_of_Week'] = df['Date Posted'].dt.day_name()  # Day name (e.g., Monday, Tuesday)\n",
    "    \n",
    "# Print out the first few rows of the dataframe after feature engineering\n",
    "print(df[['Month', 'Day', 'Hour', 'Minute', 'Day_of_Week']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828645ca",
   "metadata": {},
   "source": [
    "### Trend Analysis\n",
    "- Objective: analyze and determine the variations in user activity over time, focusing on hourly, daily, and monthly patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3526a1",
   "metadata": {},
   "source": [
    "#### 1- Visualize Overall Activity Trends Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09cfce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Set the common layout properties for all plots\n",
    "layout = dict(\n",
    "    plot_bgcolor='grey',  # Set background color to grey\n",
    "    paper_bgcolor='grey',  # Set paper background to grey\n",
    "    font=dict(color='white'),  # Set text color to white\n",
    "    hovermode='closest',\n",
    "    height=300,  # Adjust the height of the plot\n",
    "    width=600,  # Adjust the width of the plot\n",
    ")\n",
    "\n",
    "# Plot activity by hour of the day (line plot)\n",
    "hourly_activity = df.groupby('Hour').size().reindex(range(0, 24), fill_value=0)  # Ensure every hour from 0 to 23 is included\n",
    "\n",
    "fig_hourly = go.Figure()\n",
    "\n",
    "fig_hourly.add_trace(go.Scatter(\n",
    "    x=hourly_activity.index,\n",
    "    y=hourly_activity.values,\n",
    "    mode='lines+markers',\n",
    "    line=dict(color='skyblue'),\n",
    "    marker=dict(size=8, color='skyblue')\n",
    "))\n",
    "\n",
    "fig_hourly.update_layout(\n",
    "    title='Activity Distribution by Hour of the Day',\n",
    "    xaxis_title='Hour of the Day',\n",
    "    yaxis_title='Number of Posts',\n",
    "    xaxis=dict(\n",
    "        tickmode='linear', \n",
    "        tick0=0, \n",
    "        dtick=1,\n",
    "        tickangle=45  # Rotate x-axis labels by 45 degrees\n",
    "    )  \n",
    ")\n",
    "\n",
    "fig_hourly.update_layout(layout)  # Apply common layout properties\n",
    "fig_hourly.show()\n",
    "\n",
    "# Plot activity by day of the week (line plot)\n",
    "activity_by_day = df.groupby('Day_of_Week').size().reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "\n",
    "fig_day_of_week = go.Figure()\n",
    "\n",
    "fig_day_of_week.add_trace(go.Scatter(\n",
    "    x=activity_by_day.index,\n",
    "    y=activity_by_day.values,\n",
    "    mode='lines+markers',\n",
    "    line=dict(color='salmon'),\n",
    "    marker=dict(size=8, color='salmon')\n",
    "))\n",
    "\n",
    "fig_day_of_week.update_layout(\n",
    "    title='Activity Distribution by Day of the Week',\n",
    "    xaxis_title='Day of the Week',\n",
    "    yaxis_title='Number of Posts',\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=[0, 1, 2, 3, 4, 5, 6],\n",
    "        ticktext=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
    "        tickangle=45  # Rotate x-axis labels by 45 degrees\n",
    "    )\n",
    ")\n",
    "\n",
    "fig_day_of_week.update_layout(layout)  # Apply common layout properties\n",
    "fig_day_of_week.show()\n",
    "\n",
    "# Plot activity by month (line plot)\n",
    "activity_by_month = df.groupby('Month').size()\n",
    "\n",
    "fig_monthly = go.Figure()\n",
    "\n",
    "fig_monthly.add_trace(go.Scatter(\n",
    "    x=activity_by_month.index,\n",
    "    y=activity_by_month.values,\n",
    "    mode='lines+markers',\n",
    "    line=dict(color='lightgreen'),\n",
    "    marker=dict(size=8, color='lightgreen')\n",
    "))\n",
    "\n",
    "fig_monthly.update_layout(\n",
    "    title='Activity Distribution by Month',\n",
    "    xaxis_title='Month',\n",
    "    yaxis_title='Number of Posts',\n",
    "    xaxis=dict(\n",
    "        tickmode='array',  \n",
    "        tickvals=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],  # Months 1 to 12\n",
    "        ticktext=['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'],\n",
    "        tickangle=45  # Rotate x-axis labels by 45 degrees\n",
    "    )\n",
    ")\n",
    "\n",
    "fig_monthly.update_layout(layout)  # Apply common layout properties\n",
    "fig_monthly.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754c3742",
   "metadata": {},
   "source": [
    "#### 2- Identify Peak Periods of Activity using the Multivariate analysis (Correlation between Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912bb976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Identify peak activity periods (for hour of the day and day of the week)\n",
    "\n",
    "# Peak activity by hour (find the hour with the highest activity)\n",
    "peak_hour = df.groupby('Hour').size().idxmax()\n",
    "print(f\"The peak hour of activity is: {peak_hour} o'clock\")\n",
    "\n",
    "# Peak activity by day of the week (find the day with the highest activity)\n",
    "peak_day_of_week = df.groupby('Day_of_Week').size().idxmax()\n",
    "print(f\"The peak day of the week for activity is: {peak_day_of_week}\")\n",
    "\n",
    "# Optionally, plot a heatmap of activity over the day of the week and hour of the day\n",
    "activity_heatmap = df.groupby(['Day_of_Week', 'Hour']).size().unstack().fillna(0)\n",
    "\n",
    "# Set figure size and create the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Change the color set for the heatmap\n",
    "sns.heatmap(activity_heatmap, cmap=\"magma\", annot=True, fmt=\"d\", cbar_kws={'label': 'Number of Posts'})\n",
    "\n",
    "# Titles and labels\n",
    "plt.title('Heatmap of Activity by Day of the Week and Hour of the Day')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Day of the Week')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff6221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify peak activity periods (for hour of the day and day of the week)\n",
    "\n",
    "# Peak activity by hour (find the hour with the highest activity)\n",
    "peak_hour = df.groupby('Hour').size().idxmax()\n",
    "print(f\"The peak hour of activity is: {peak_hour} o'clock\")\n",
    "\n",
    "# Peak activity by day of the week (find the day with the highest activity)\n",
    "peak_day_of_week = df.groupby('Day_of_Week').size().idxmax()\n",
    "print(f\"The peak day of the week for activity is: {peak_day_of_week}\")\n",
    "\n",
    "# Optionally, plot a heatmap of activity over the day of the week and hour of the day\n",
    "activity_heatmap = df.groupby(['Day_of_Week', 'Hour']).size().unstack().fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(activity_heatmap, cmap=\"YlGnBu\", annot=True, fmt=\"d\")\n",
    "plt.title('Heatmap of Activity by Day of the Week and Hour of the Day')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Day of the Week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe87b36",
   "metadata": {},
   "source": [
    "### Encode Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"# Check the shape of your DataFrame\\n\",\n",
    "    \"print(\\\"Original DataFrame shape:\\\", df.shape)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Map 'Day_of_Week' to 'Weekday' and 'Weekend'\\n\",\n",
    "    \"weekday_to_weekend = {\\n\",\n",
    "    \"    'Monday': 'Weekday', 'Tuesday': 'Weekday', 'Wednesday': 'Weekday', 'Thursday': 'Weekday', 'Friday': 'Weekday',\\n\",\n",
    "    \"    'Saturday': 'Weekend', 'Sunday': 'Weekend'\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create a new column 'Day_Type' that classifies days as 'Weekday' or 'Weekend'\\n\",\n",
    "    \"df['Day_Type'] = df['Day_of_Week'].map(weekday_to_weekend)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Apply LabelEncoder to the 'Day_Type' column to get numeric encoding\\n\",\n",
    "    \"label_encoder = LabelEncoder()\\n\",\n",
    "    \"df['Day_Type_encoded'] = label_encoder.fit_transform(df['Day_Type'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 6: Verify the DataFrame's shape remains the same\\n\",\n",
    "    \"print(\\\"New DataFrame shape:\\\", df.shape)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display the first few rows to confirm the encoding\\n\",\n",
    "    \"print(df[['Day_of_Week', 'Day_Type', 'Day_Type_encoded']].head())\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea4dc1",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"# Compute basic statistics for weekdays and weekends\\n\",\n",
    "    \"weekday_data = df[df['Day_Type_encoded'] == 0]  # Weekdays\\n\",\n",
    "    \"weekend_data = df[df['Day_Type_encoded'] == 1]  # Weekends\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Get the count of posts per day of the week for weekdays and weekends\\n\",\n",
    "    \"weekday_counts = weekday_data['Day_of_Week'].value_counts()\\n\",\n",
    "    \"weekend_counts = weekend_data['Day_of_Week'].value_counts()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Get average hour of activity for weekdays and weekends\\n\",\n",
    "    \"weekday_avg_hour = weekday_data['Hour'].mean()\\n\",\n",
    "    \"weekend_avg_hour = weekend_data['Hour'].mean()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Weekday Counts:\\\")\\n\",\n",
    "    \"print(weekday_counts)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nWeekend Counts:\\\")\\n\",\n",
    "    \"print(weekend_counts)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nAverage Hour for Weekdays: {weekday_avg_hour}\\\")\\n\",\n",
    "    \"print(f\\\"Average Hour for Weekends: {weekend_avg_hour}\\\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c35ded",
   "metadata": {},
   "source": [
    "### Time Series Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5800515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"import statsmodels.api as sm\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Convert the 'Date Posted' to datetime if it's not already\\n\",\n",
    "    \"df['Date Posted'] = pd.to_datetime(df['Date Posted'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set Date Posted as the index\\n\",\n",
    "    \"df.set_index('Date Posted', inplace=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Resample the data to daily frequency and get the count of posts\\n\",\n",
    "    \"daily_posts = df.resample('D').size()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Decompose the time series\\n\",\n",
    "    \"decomposition = sm.tsa.seasonal_decompose(daily_posts, model='additive', period=365)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot the decomposition\\n\",\n",
    "    \"decomposition.plot()\\n\",\n",
    "    \"plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1732d",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec313596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Boxplot to visualize the distribution of activity by Hour and Day_Type_encoded\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"sns.boxplot(data=df, x='Day_Type_encoded', y='Hour', palette='coolwarm')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Customize plot\\n\",\n",
    "    \"plt.title('Activity Distribution by Hour and Day Type (Weekday vs Weekend)')\\n\",\n",
    "    \"plt.xlabel('Day Type')\\n\",\n",
    "    \"plt.ylabel('Hour of the Day')\\n\",\n",
    "    \"plt.xticks([0, 1], ['Weekday', 'Weekend'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Show the plot\\n\",\n",
    "    \"plt.show()\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95835732",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"### Classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4cdb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"from sklearn.linear_model import LogisticRegression\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from sklearn.metrics import classification_report\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Features and target\\n\",\n",
    "    \"X = df[['Hour']]  # Use Hour as a feature\\n\",\n",
    "    \"y = df['Day_Type_encoded']  # Target: Weekday (0) or Weekend (1)\\n\",\n",
    "    \"\\n\",\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"#### 1- Prepare Data for Classification\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be878f",
   "metadata": {},
   "source": [
    "#### 2- Split Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    " \"# Split the data into train and test sets\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize and train the model\\n\",\n",
    "    \"model = LogisticRegression()\\n\",\n",
    "    \"model.fit(X_train, y_train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Predict the test set\\n\",\n",
    "    \"y_pred = model.predict(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Evaluate the model\\n\",\n",
    "    \"print(classification_report(y_test, y_pred))\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727296a2",
   "metadata": {},
   "source": [
    "#### 3- Build and Train the Classifier (e.g., Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a0ceb6",
   "metadata": {},
   "source": [
    "#### 4- Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d113e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d9ee3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36e07f73",
   "metadata": {},
   "source": [
    "### Normalize the data using Min-Max scaling (which transforms the data to a range between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c52a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"from sklearn.preprocessing import MinMaxScaler\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize the scaler\\n\",\n",
    "    \"scaler = MinMaxScaler()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Normalize the selected columns\\n\",\n",
    "    \"df[['Month', 'Day', 'Hour', 'Minute']] = scaler.fit_transform(df[['Month', 'Day', 'Hour', 'Minute']])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Print the normalized data\\n\",\n",
    "    \"print(df[['Month', 'Day', 'Hour', 'Minute']].head().round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7477ba0",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b72576",
   "metadata": {},
   "source": [
    "### Pattern Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322d204e",
   "metadata": {},
   "source": [
    "#### 1- Apply Association Rule Mining or Sequence Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4285e199",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "https://www.kaggle.com/datasets/vasileiosmpletsos/1100-instagram-users-datetime-posts-data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
